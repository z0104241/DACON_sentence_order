#!/usr/bin/env python3
"""
ë¬¸ì¥ ìˆœì„œ ì˜ˆì¸¡ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
Qwen3-8B + PEFT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì¥ ìˆœì„œë¥¼ ì˜ˆì¸¡í•˜ê³  CSVë¡œ ì €ì¥
"""

import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
import re
from tqdm import tqdm
import argparse
import os

# ì„¤ì •
MODEL_NAME = "Qwen/Qwen3-8B"
MODEL_PATH = "qwen3_model"  # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ

def load_model_and_tokenizer():
    """ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ"""
    
    print("ğŸ”§ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    
    # í† í¬ë‚˜ì´ì €
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)
    
    # ë² ì´ìŠ¤ ëª¨ë¸
    base_model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME,
        device_map="auto",
        trust_remote_code=True,
        torch_dtype='auto'
    )
    
    # í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    model = PeftModel.from_pretrained(base_model, MODEL_PATH)
    model.eval()
    
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    return model, tokenizer

def predict_order(sentences, model, tokenizer):
    """ê¸´ì¶”ë¡  ë°©ì‹ìœ¼ë¡œ ë¬¸ì¥ ìˆœì„œ ì˜ˆì¸¡"""
    
    prompt = f"""ë‹¤ìŒ ë¬¸ì¥ë“¤ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” ìˆœì„œë¡œ ì¬ë°°ì—´í•˜ì„¸ìš”.

ë¬¸ì¥ë“¤:
0: {sentences[0]}
1: {sentences[1]}
2: {sentences[2]}
3: {sentences[3]}

ë‹¨ê³„ë³„ë¡œ ë¶„ì„í•´ë³´ê³  ìµœì¢… ìˆœì„œë¥¼ ìˆ«ìë¡œ ë‹µí•˜ì„¸ìš”:"""

    messages = [{"role": "user", "content": prompt}]
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = tokenizer(text, return_tensors="pt").to(model.device)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=150,
            temperature=0.8,
            top_p=0.9,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
            repetition_penalty=1.05
        )
    
    input_length = inputs.input_ids.shape[1]
    generated = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True).strip()
    
    # ìˆœì„œ ì¶”ì¶œ
    order = extract_final_order(generated)
    return order

def extract_final_order(text):
    """í…ìŠ¤íŠ¸ì—ì„œ ìµœì¢… ìˆœì„œ ì¶”ì¶œ"""
    
    # 4ìë¦¬ ì—°ì† ìˆ«ì ìš°ì„ 
    four_digit = re.search(r'\b([0-3]{4})\b', text)
    if four_digit:
        return four_digit.group(1)
    
    # ë§ˆì§€ë§‰ ë¼ì¸ì—ì„œ ìˆ«ìë“¤
    lines = text.split('\n')
    for line in reversed(lines):
        numbers = re.findall(r'[0-3]', line)
        if len(numbers) >= 4:
            return ''.join(numbers[:4])
    
    # ì „ì²´ì—ì„œ ìˆ«ìë“¤
    all_numbers = re.findall(r'[0-3]', text)
    if len(all_numbers) >= 4:
        return ''.join(all_numbers[-4:])
    
    return "0123"

def load_test_data(file_path):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    
    print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ: {file_path}")
    df = pd.read_csv(file_path)
    print(f"   ë°ì´í„° í¬ê¸°: {df.shape}")
    
    return df

def extract_sentences_from_row(row):
    """í–‰ì—ì„œ ë¬¸ì¥ë“¤ ì¶”ì¶œ"""
    
    # ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… ì‹œë„
    column_patterns = [
        ['sentence_0', 'sentence_1', 'sentence_2', 'sentence_3'],
        ['sent_0', 'sent_1', 'sent_2', 'sent_3'],
        ['text_0', 'text_1', 'text_2', 'text_3'],
        ['0', '1', '2', '3']
    ]
    
    for pattern in column_patterns:
        try:
            sentences = [row[col] for col in pattern]
            return sentences
        except KeyError:
            continue
    
    # ë§ˆì§€ë§‰ ì‹œë„: ì²˜ìŒ 4ê°œ ì»¬ëŸ¼
    try:
        sentences = [row.iloc[i] for i in range(4)]
        return sentences
    except:
        raise ValueError("ë¬¸ì¥ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def predict_all_rows(df, model, tokenizer):
    """dfì˜ ëª¨ë“  í–‰ì— ëŒ€í•´ ìˆœì„œ ì˜ˆì¸¡"""
    
    print(f"ğŸš€ ì´ {len(df)}ê°œ í–‰ ì²˜ë¦¬ ì‹œì‘...")
    print("=" * 60)
    
    results = []
    error_count = 0
    
    # ì§„í–‰ë°” í¬í•¨ ë°˜ë³µ
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="ìˆœì„œ ì˜ˆì¸¡"):
        
        try:
            # ë¬¸ì¥ë“¤ ì¶”ì¶œ
            sentences = extract_sentences_from_row(row)
            
            # ìˆœì„œ ì˜ˆì¸¡
            predicted_order = predict_order(sentences, model, tokenizer)
            
            # ì˜ˆì¸¡ ìˆœì„œë¥¼ ê°œë³„ ì»¬ëŸ¼ìœ¼ë¡œ ë¶„ë¦¬
            if len(predicted_order) == 4 and predicted_order.isdigit():
                answer_0 = int(predicted_order[0])
                answer_1 = int(predicted_order[1])
                answer_2 = int(predicted_order[2])
                answer_3 = int(predicted_order[3])
            else:
                # ê¸¸ì´ê°€ 4ê°€ ì•„ë‹ˆë©´ ê¸°ë³¸ê°’
                answer_0, answer_1, answer_2, answer_3 = 0, 1, 2, 3
                error_count += 1
            
            results.append({
                'ID': f'TEST_{idx:04d}',
                'answer_0': answer_0,
                'answer_1': answer_1,
                'answer_2': answer_2,
                'answer_3': answer_3
            })
        
        except Exception as e:
            print(f"âŒ í–‰ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            error_count += 1
            # ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ê°€
            results.append({
                'ID': f'TEST_{idx:04d}',
                'answer_0': 0,
                'answer_1': 1,
                'answer_2': 2,
                'answer_3': 3
            })
            continue
    
    print("=" * 60)
    print(f"âœ… ì™„ë£Œ! {len(results)}ê°œ í–‰ ì²˜ë¦¬ë¨")
    if error_count > 0:
        print(f"âš ï¸  {error_count}ê°œ í–‰ì—ì„œ ì˜¤ë¥˜ ë°œìƒ (ê¸°ë³¸ê°’ ì‚¬ìš©)")
    
    return results

def analyze_results(results):
    """ê²°ê³¼ ë¶„ì„ ë° í†µê³„"""
    
    # ìˆœì„œ ì¬êµ¬ì„±í•´ì„œ ë¶„ì„
    orders = []
    for r in results:
        order = f"{r['answer_0']}{r['answer_1']}{r['answer_2']}{r['answer_3']}"
        orders.append(order)
    
    unique_orders = set(orders)
    
    print(f"\nğŸ“Š ê²°ê³¼ ë¶„ì„:")
    print(f"ì´ {len(unique_orders)}ê°€ì§€ ìˆœì„œ íŒ¨í„´")
    print("-" * 30)
    
    # ë¹ˆë„ìˆœ ì •ë ¬
    order_counts = {order: orders.count(order) for order in unique_orders}
    sorted_orders = sorted(order_counts.items(), key=lambda x: x[1], reverse=True)
    
    # ìƒìœ„ 10ê°œë§Œ ì¶œë ¥
    for order, count in sorted_orders[:10]:
        percentage = (count / len(orders)) * 100
        print(f"{order}: {count:4d}ë²ˆ ({percentage:5.1f}%)")
    
    if len(sorted_orders) > 10:
        print(f"... ({len(sorted_orders) - 10}ê°€ì§€ ë”)")
    
    # ë‹¤ì–‘ì„± ì§€ìˆ˜
    diversity = len(unique_orders) / len(orders) * 100
    print(f"\nğŸ¯ ë‹¤ì–‘ì„± ì§€ìˆ˜: {diversity:.1f}%")
    
    if diversity < 10:
        print("âš ï¸  ë§¤ìš° ë‚®ì€ ë‹¤ì–‘ì„± - ì‹¬ê°í•œ í¸í–¥")
    elif diversity < 25:
        print("ğŸ”¶ ë‚®ì€ ë‹¤ì–‘ì„± - ì¼ë¶€ í¸í–¥ ì¡´ì¬") 
    elif diversity < 50:
        print("ğŸ”µ ë³´í†µ ë‹¤ì–‘ì„±")
    else:
        print("âœ… ë†’ì€ ë‹¤ì–‘ì„± - ì¢‹ì€ ì„±ëŠ¥")

def save_results(results, filename):
    """ê²°ê³¼ë¥¼ ì§€ì •ëœ í˜•ì‹ì˜ CSVë¡œ ì €ì¥"""
    
    results_df = pd.DataFrame(results)
    
    # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
    results_df = results_df[['ID', 'answer_0', 'answer_1', 'answer_2', 'answer_3']]
    
    # CSV ì €ì¥
    results_df.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"ğŸ’¾ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    return results_df

def main(input_file, output_file):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ¯ ë¬¸ì¥ ìˆœì„œ ì˜ˆì¸¡ ì¶”ë¡  ì‹œì‘!")
    print("=" * 60)
    
    # 1. ëª¨ë¸ ë¡œë“œ
    model, tokenizer = load_model_and_tokenizer()
    
    # 2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    df = load_test_data(input_file)
    
    # 3. ì „ì²´ ì˜ˆì¸¡
    results = predict_all_rows(df, model, tokenizer)
    
    # 4. ê²°ê³¼ ë¶„ì„
    analyze_results(results)
    
    # 5. ê²°ê³¼ ì €ì¥
    results_df = save_results(results, output_file)
    
    print(f"\nğŸ‰ ì¶”ë¡  ì™„ë£Œ!")
    print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {input_file}")
    print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_file}")
    print(f"ğŸ“Š ì²˜ë¦¬ëœ ìƒ˜í”Œ: {len(results)}ê°œ")
    
    return results, results_df

if __name__ == "__main__":
    
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(description='ë¬¸ì¥ ìˆœì„œ ì˜ˆì¸¡ ì¶”ë¡ ')
    parser.add_argument('--input', '-i', default='test.csv', 
                      help='ì…ë ¥ CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: test.csv)')
    parser.add_argument('--output', '-o', default='prediction_results.csv',
                      help='ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: prediction_results.csv)')
    
    args = parser.parse_args()
    
    try:
        # ë©”ì¸ ì‹¤í–‰
        results, results_df = main(args.input, args.output)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ì‚¬ìš©ë²•: python inference.py --input test.csv --output results.csv")